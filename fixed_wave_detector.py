import cv2
import os
import numpy as np
from ultralytics import YOLO
from datetime import datetime
from collections import deque, defaultdict
import math

class SimpleWaveDetector:
    """åŸºäºå®½é«˜æ¯”çš„ç®€åŒ–æŒ¥æ‰‹æ£€æµ‹å™¨"""
    
    def __init__(self, wave_aspect_ratio_min=0.7, min_wave_duration=2):
        self.wave_aspect_ratio_min = wave_aspect_ratio_min
        self.min_wave_duration = min_wave_duration
        self.wave_counters = defaultdict(int)
        
    def detect_wave(self, track_id, bbox):
        """æ£€æµ‹æŒ¥æ‰‹ï¼šåŸºäºå®½é«˜æ¯”"""
        x1, y1, x2, y2, conf = bbox
        width = x2 - x1
        height = y2 - y1
        
        if height <= 0:
            return False, 0
        
        aspect_ratio = width / height
        
        # åˆ¤æ–­å½“å‰å¸§æ˜¯å¦ä¸ºæŒ¥æ‰‹çŠ¶æ€
        is_current_wave = aspect_ratio >= self.wave_aspect_ratio_min
        
        if is_current_wave:
            self.wave_counters[track_id] += 1
        else:
            self.wave_counters[track_id] = 0
        
        # æŒç»­æŒ¥æ‰‹æ‰ç®—çœŸæ­£çš„æŒ¥æ‰‹
        is_waving = self.wave_counters[track_id] >= self.min_wave_duration
        
        return is_waving, aspect_ratio

def analyze_video_with_fixed_encoding(video_path, show_video=True, save_output=True):
    """ä¿®å¤äº†ç¼–ç é—®é¢˜çš„è§†é¢‘åˆ†æ"""
    print(f"=== ä¿®å¤ç‰ˆæŒ¥æ‰‹æ£€æµ‹ ===")
    print(f"è§†é¢‘æ–‡ä»¶: {video_path}")
    
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # åŠ è½½YOLOäººç‰©æ£€æµ‹æ¨¡å‹
    model = YOLO('yolov8n.pt')
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"é”™è¯¯ï¼šæ— æ³•æ‰“å¼€è§†é¢‘")
        return False
    
    # è·å–è§†é¢‘å±æ€§
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"è§†é¢‘å±æ€§: {width}x{height}, {fps:.1f}fps, {total_frames}å¸§")
    
    # ä¿®å¤å¸§ç‡é—®é¢˜
    if fps <= 0 or fps > 120:
        fps = 25.0
        print(f"ä¿®å¤å¸§ç‡ä¸º: {fps}")
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    wave_detector = SimpleWaveDetector(wave_aspect_ratio_min=0.7, min_wave_duration=2)
    
    # å‡†å¤‡è¾“å‡ºè§†é¢‘ - ä½¿ç”¨å¤šç§ç¼–ç å™¨å°è¯•
    output_writer = None
    output_path = None
    
    if save_output:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "fixed_wave_analysis"
        os.makedirs(output_dir, exist_ok=True)
        
        # å°è¯•ä¸åŒçš„ç¼–ç å™¨å’Œæ ¼å¼
        encoders_to_try = [
            ('avi', 'XVID'),  # æœ€å…¼å®¹çš„ç»„åˆ
            ('mp4', 'mp4v'),  # æ ‡å‡†MP4
            ('mov', 'mp4v'),  # MOVæ ¼å¼
        ]
        
        for ext, codec in encoders_to_try:
            output_path = os.path.join(output_dir, f"{video_name}_fixed_wave_{timestamp}.{ext}")
            fourcc = cv2.VideoWriter.fourcc(*codec)
            output_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            if output_writer.isOpened():
                print(f"âœ… è¾“å‡ºè§†é¢‘: {output_path} (ç¼–ç å™¨: {codec})")
                break
            else:
                print(f"âŒ ç¼–ç å™¨ {codec} å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                output_writer = None
        
        if output_writer is None:
            print("âš ï¸ æ‰€æœ‰ç¼–ç å™¨éƒ½å¤±è´¥ï¼Œå°†ä¸ä¿å­˜è§†é¢‘")
    
    # ç®€å•çš„äººç‰©è·Ÿè¸ª - ä½¿ç”¨ä½ç½®è·ç¦»
    person_tracks = {}
    next_id = 0
    max_distance = 100
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_frames': 0,
        'frames_with_persons': 0,
        'frames_with_waves': 0,
        'high_aspect_ratio_count': 0
    }
    
    frame_count = 0
    
    print(f"\nå¼€å§‹åˆ†æ... (æŒ‰ 'q' é€€å‡º)")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            stats['total_frames'] = frame_count
            
            # ä½¿ç”¨YOLOæ£€æµ‹äººç‰©
            results = model(frame, conf=0.3, verbose=False)[0]
            boxes = results.boxes
            
            # æå–äººç‰©æ£€æµ‹ç»“æœ
            current_detections = []
            if boxes is not None and len(boxes) > 0:
                for box in boxes:
                    cls_id = int(box.cls[0])
                    if cls_id == 0:  # äººç±»
                        conf_score = float(box.conf[0])
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        center_x = (x1 + x2) / 2
                        center_y = (y1 + y2) / 2
                        current_detections.append((x1, y1, x2, y2, conf_score, center_x, center_y))
            
            if current_detections:
                stats['frames_with_persons'] += 1
            
            # ç®€å•çš„è·Ÿè¸ªï¼šåŒ¹é…æœ€è¿‘çš„æ£€æµ‹ç»“æœ
            matched_tracks = {}
            unmatched_detections = current_detections.copy()
            
            # ä¸ºç°æœ‰è½¨è¿¹æ‰¾åŒ¹é…
            for track_id, last_center in person_tracks.items():
                best_match = None
                best_distance = float('inf')
                
                for i, detection in enumerate(unmatched_detections):
                    x1, y1, x2, y2, conf, center_x, center_y = detection
                    distance = math.sqrt((center_x - last_center[0])**2 + (center_y - last_center[1])**2)
                    
                    if distance < max_distance and distance < best_distance:
                        best_distance = distance
                        best_match = i
                
                if best_match is not None:
                    detection = unmatched_detections.pop(best_match)
                    matched_tracks[track_id] = detection
            
            # ä¸ºæœªåŒ¹é…çš„æ£€æµ‹åˆ›å»ºæ–°è½¨è¿¹
            for detection in unmatched_detections:
                matched_tracks[next_id] = detection
                next_id += 1
            
            # æ›´æ–°è½¨è¿¹
            person_tracks = {}
            current_frame_has_wave = False
            
            for track_id, detection in matched_tracks.items():
                x1, y1, x2, y2, conf, center_x, center_y = detection
                person_tracks[track_id] = (center_x, center_y)
                
                # æ£€æµ‹æŒ¥æ‰‹
                bbox = (x1, y1, x2, y2, conf)
                is_waving, aspect_ratio = wave_detector.detect_wave(track_id, bbox)
                
                # ç»Ÿè®¡é«˜å®½é«˜æ¯”
                if aspect_ratio >= 0.7:
                    stats['high_aspect_ratio_count'] += 1
                
                # ç»˜åˆ¶ç»“æœ
                if is_waving:
                    color = (0, 255, 0)  # ç»¿è‰² - æŒ¥æ‰‹
                    label = f"ID{track_id}: WAVING ({aspect_ratio:.2f})"
                    current_frame_has_wave = True
                elif aspect_ratio >= 0.7:
                    color = (0, 255, 255)  # é»„è‰² - å¯èƒ½æŒ¥æ‰‹
                    label = f"ID{track_id}: MAYBE ({aspect_ratio:.2f})"
                else:
                    color = (255, 0, 0)  # è“è‰² - æ­£å¸¸
                    label = f"ID{track_id}: Normal ({aspect_ratio:.2f})"
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            if current_frame_has_wave:
                stats['frames_with_waves'] += 1
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            info_text = f"Frame: {frame_count}/{total_frames} | Persons: {len(matched_tracks)} | Waves: {stats['frames_with_waves']}"
            cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            threshold_text = f"Threshold: Aspect Ratio >= 0.7, Duration >= 2 frames"
            cv2.putText(frame, threshold_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # ä¿å­˜è§†é¢‘å¸§
            if output_writer:
                output_writer.write(frame)
            
            # æ˜¾ç¤ºè§†é¢‘
            if show_video:
                cv2.imshow('Fixed Wave Detection', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            # è¿›åº¦æŠ¥å‘Š
            if frame_count % 200 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"è¿›åº¦: {progress:.1f}% - æŒ¥æ‰‹å¸§: {stats['frames_with_waves']}, é«˜å®½é«˜æ¯”: {stats['high_aspect_ratio_count']}")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    
    # æ¸…ç†èµ„æº
    cap.release()
    if output_writer:
        output_writer.release()
    if show_video:
        cv2.destroyAllWindows()
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\n=== åˆ†æç»“æœ ===")
    print(f"æ€»å¸§æ•°: {stats['total_frames']}")
    print(f"æœ‰äººç‰©å¸§æ•°: {stats['frames_with_persons']}")
    print(f"æ£€æµ‹åˆ°æŒ¥æ‰‹å¸§æ•°: {stats['frames_with_waves']}")
    print(f"é«˜å®½é«˜æ¯”(>=0.7)æ¬¡æ•°: {stats['high_aspect_ratio_count']}")
    
    if stats['frames_with_persons'] > 0:
        wave_rate = (stats['frames_with_waves'] / stats['frames_with_persons']) * 100
        print(f"æŒ¥æ‰‹æ£€æµ‹ç‡: {wave_rate:.1f}%")
    
    if output_path and os.path.exists(output_path):
        file_size = os.path.getsize(output_path) / (1024*1024)  # MB
        print(f"\nâœ… è¾“å‡ºè§†é¢‘å·²ä¿å­˜: {output_path}")
        print(f"æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å¯ä»¥æ‰“å¼€
        test_cap = cv2.VideoCapture(output_path)
        if test_cap.isOpened():
            print("âœ… è¾“å‡ºè§†é¢‘æ–‡ä»¶éªŒè¯æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸æ‰“å¼€")
            test_cap.release()
        else:
            print("âŒ è¾“å‡ºè§†é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    video_path = r"C:\c\wave_hands\test_videos_20250622_100947\B605_3min_20250622_100957.mov"
    
    print("=== ä¿®å¤ç‰ˆæŒ¥æ‰‹æ£€æµ‹ç®—æ³• ===")
    print("ä¿®å¤äº†ä»¥ä¸‹é—®é¢˜ï¼š")
    print("1. è§†é¢‘ç¼–ç å™¨å…¼å®¹æ€§é—®é¢˜")
    print("2. MOVæ–‡ä»¶å¤„ç†é—®é¢˜")
    print("3. å¸§ç‡å¼‚å¸¸å¤„ç†")
    print("4. ç®€åŒ–äº†ç®—æ³•é€»è¾‘")
    
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    success = analyze_video_with_fixed_encoding(
        video_path=video_path,
        show_video=True,
        save_output=True
    )
    
    if success:
        print("\nğŸ‰ ä¿®å¤ç‰ˆç®—æ³•æµ‹è¯•å®Œæˆï¼")
        print("\nä¸»è¦æ”¹è¿›:")
        print("- ä½¿ç”¨AVI+XVIDç¼–ç å™¨ï¼ˆæœ€å…¼å®¹ï¼‰")
        print("- è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤å¸§ç‡é—®é¢˜")
        print("- ç®€åŒ–äº†äººç‰©è·Ÿè¸ªé€»è¾‘")
        print("- é™ä½äº†æŒ¥æ‰‹æŒç»­æ—¶é—´è¦æ±‚(2å¸§)")

if __name__ == '__main__':
    main() 