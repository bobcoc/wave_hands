import cv2
import yaml
import os
import sys
import time
import numpy as np
from ultralytics import YOLO
from datetime import datetime

def load_config(config_path='config.yaml'):
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def analyze_person_detection(video_path, config, save_samples=True):
    """
    ä¸¤é˜¶æ®µæ£€æµ‹åˆ†æï¼š
    1. ä½¿ç”¨é¢„è®­ç»ƒYOLOæ£€æµ‹äººç‰©
    2. åœ¨äººç‰©åŒºåŸŸåŸºç¡€ä¸Šåˆ†ææŒ¥æ‰‹åŠ¨ä½œ
    """
    print("=== ä¸¤é˜¶æ®µæ£€æµ‹åˆ†æ ===")
    print("é˜¶æ®µ1: äººç‰©æ£€æµ‹ (ä½¿ç”¨é¢„è®­ç»ƒYOLO)")
    print("é˜¶æ®µ2: æŒ¥æ‰‹åŠ¨ä½œåˆ†æ (åœ¨äººç‰©åŒºåŸŸå†…)")
    
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return False
    
    # åŠ è½½ä¸¤ä¸ªæ¨¡å‹
    # 1. é¢„è®­ç»ƒçš„YOLOæ¨¡å‹ç”¨äºäººç‰©æ£€æµ‹
    try:
        person_model = YOLO('yolov8n.pt')  # é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…å«personç±»
        print("âœ“ äººç‰©æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âœ— äººç‰©æ£€æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. è‡ªå®šä¹‰çš„æŒ¥æ‰‹æ£€æµ‹æ¨¡å‹
    weights = config.get('weights', 'weight/best.pt')
    if os.path.exists(weights):
        try:
            wave_model = YOLO(weights, task='detect')
            print("âœ“ æŒ¥æ‰‹æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
            has_wave_model = True
        except Exception as e:
            print(f"âš ï¸  æŒ¥æ‰‹æ£€æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            has_wave_model = False
    else:
        print(f"âš ï¸  æŒ¥æ‰‹æ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {weights}")
        has_wave_model = False
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"é”™è¯¯ï¼šæ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return False
    
    # è·å–è§†é¢‘å±æ€§
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"\nè§†é¢‘å±æ€§:")
    print(f"  åˆ†è¾¨ç‡: {width}x{height}")
    print(f"  å¸§ç‡: {fps:.1f}fps")
    print(f"  æ€»å¸§æ•°: {total_frames}")
    print(f"  æ—¶é•¿: {duration:.1f}ç§’")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_frames': 0,
        'frames_with_person': 0,
        'persons_detected': 0,
        'wave_in_person_area': 0,
        'nowave_in_person_area': 0,
        'direct_wave_detection': 0,
        'direct_nowave_detection': 0
    }
    
    # ä¿å­˜æ ·æœ¬çš„è®¾ç½®
    if save_samples:
        sample_dir = "person_detection_samples"
        os.makedirs(sample_dir, exist_ok=True)
        sample_interval = max(1, total_frames // 20)  # ä¿å­˜20ä¸ªæ ·æœ¬
        sample_count = 0
    
    print(f"\nå¼€å§‹åˆ†æ...")
    
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            stats['total_frames'] = frame_count
            
            # åˆ›å»ºå±•ç¤ºå¸§çš„å‰¯æœ¬
            display_frame = frame.copy()
            
            # === é˜¶æ®µ1: äººç‰©æ£€æµ‹ ===
            person_results = person_model(frame, conf=0.3, verbose=False)[0]
            person_boxes = person_results.boxes
            
            persons_in_frame = []
            
            if person_boxes is not None:
                for box in person_boxes:
                    cls_id = int(box.cls[0])
                    conf_score = float(box.conf[0])
                    
                    # COCOæ•°æ®é›†ä¸­ï¼Œpersonçš„class_idæ˜¯0
                    if cls_id == 0 and conf_score >= 0.3:
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        persons_in_frame.append({
                            'bbox': [x1, y1, x2, y2],
                            'confidence': conf_score
                        })
                        stats['persons_detected'] += 1
                        
                        # ç»˜åˆ¶äººç‰©æ£€æµ‹æ¡†ï¼ˆè“è‰²ï¼‰
                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(display_frame, f"Person {conf_score:.2f}", 
                                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
            
            if persons_in_frame:
                stats['frames_with_person'] += 1
            
            # === é˜¶æ®µ2: åœ¨äººç‰©åŒºåŸŸå†…è¿›è¡ŒæŒ¥æ‰‹æ£€æµ‹ ===
            wave_detections_in_person = []
            direct_wave_detections = []
            
            if has_wave_model:
                # å¯¹æ•´ä¸ªç”»é¢è¿›è¡ŒæŒ¥æ‰‹æ£€æµ‹
                wave_results = wave_model(frame, conf=0.1, verbose=False)[0]
                wave_boxes = wave_results.boxes
                
                if wave_boxes is not None:
                    for box in wave_boxes:
                        cls_id = int(box.cls[0])
                        conf_score = float(box.conf[0])
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        
                        detection_info = {
                            'bbox': [x1, y1, x2, y2],
                            'class_id': cls_id,
                            'confidence': conf_score,
                            'class_name': config.get('names', ['wave', 'nowave'])[cls_id]
                        }
                        
                        # æ£€æŸ¥æŒ¥æ‰‹æ£€æµ‹æ˜¯å¦åœ¨äººç‰©åŒºåŸŸå†…
                        is_in_person_area = False
                        for person in persons_in_frame:
                            if bbox_overlap(detection_info['bbox'], person['bbox']):
                                is_in_person_area = True
                                wave_detections_in_person.append(detection_info)
                                
                                if cls_id == 0:  # wave
                                    stats['wave_in_person_area'] += 1
                                elif cls_id == 1:  # nowave
                                    stats['nowave_in_person_area'] += 1
                                break
                        
                        if not is_in_person_area:
                            direct_wave_detections.append(detection_info)
                            
                            if cls_id == 0:  # wave
                                stats['direct_wave_detection'] += 1
                            elif cls_id == 1:  # nowave
                                stats['direct_nowave_detection'] += 1
                        
                        # ç»˜åˆ¶æŒ¥æ‰‹æ£€æµ‹ç»“æœ
                        if is_in_person_area:
                            color = (0, 255, 0) if cls_id == 0 else (0, 255, 255)  # ç»¿è‰²(wave) æˆ– é’è‰²(nowave)
                            label = f"âœ“{detection_info['class_name']} {conf_score:.2f}"
                        else:
                            color = (128, 128, 128)  # ç°è‰² - ä¸åœ¨äººç‰©åŒºåŸŸå†…
                            label = f"âœ—{detection_info['class_name']} {conf_score:.2f}"
                        
                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                        cv2.putText(display_frame, label, (x1, y1-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # åœ¨å¸§ä¸Šæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            info_lines = [
                f"Frame: {frame_count}/{total_frames}",
                f"Persons: {len(persons_in_frame)}",
                f"Wave in Person: {len([d for d in wave_detections_in_person if d['class_id']==0])}",
                f"NoWave in Person: {len([d for d in wave_detections_in_person if d['class_id']==1])}",
                f"Direct Wave: {len([d for d in direct_wave_detections if d['class_id']==0])}",
                f"Direct NoWave: {len([d for d in direct_wave_detections if d['class_id']==1])}"
            ]
            
            for i, line in enumerate(info_lines):
                cv2.putText(display_frame, line, (10, 30 + i*25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # ä¿å­˜æ ·æœ¬å¸§
            if save_samples and frame_count % sample_interval == 0:
                sample_path = os.path.join(sample_dir, 
                    f"sample_{sample_count:03d}_frame_{frame_count}_person_{len(persons_in_frame)}_wave_{len(wave_detections_in_person)}.jpg")
                cv2.imwrite(sample_path, display_frame)
                sample_count += 1
                
                print(f"æ ·æœ¬ {sample_count}: å¸§{frame_count}, äººç‰©:{len(persons_in_frame)}, "
                      f"äººç‰©åŒºåŸŸå†…æŒ¥æ‰‹:{len(wave_detections_in_person)}")
            
            # æ¯100å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if frame_count % 100 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"è¿›åº¦: {progress:.1f}% - äººç‰©å¸§:{stats['frames_with_person']}, "
                      f"æ€»äººæ•°:{stats['persons_detected']}, "
                      f"äººç‰©åŒºåŸŸå†…æŒ¥æ‰‹:{stats['wave_in_person_area'] + stats['nowave_in_person_area']}")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­åˆ†æ")
    
    cap.release()
    
    # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ç»“æœ
    print(f"\n=== åˆ†æç»“æœç»Ÿè®¡ ===")
    print(f"æ€»å¸§æ•°: {stats['total_frames']}")
    print(f"åŒ…å«äººç‰©çš„å¸§æ•°: {stats['frames_with_person']} ({stats['frames_with_person']/stats['total_frames']*100:.1f}%)")
    print(f"æ£€æµ‹åˆ°çš„æ€»äººæ•°: {stats['persons_detected']}")
    print(f"å¹³å‡æ¯å¸§äººæ•°: {stats['persons_detected']/stats['total_frames']:.2f}")
    
    print(f"\n=== æŒ¥æ‰‹æ£€æµ‹ç»“æœ ===")
    print(f"äººç‰©åŒºåŸŸå†…çš„Waveæ£€æµ‹: {stats['wave_in_person_area']}")
    print(f"äººç‰©åŒºåŸŸå†…çš„NoWaveæ£€æµ‹: {stats['nowave_in_person_area']}")
    print(f"äººç‰©åŒºåŸŸå¤–çš„Waveæ£€æµ‹: {stats['direct_wave_detection']}")
    print(f"äººç‰©åŒºåŸŸå¤–çš„NoWaveæ£€æµ‹: {stats['direct_nowave_detection']}")
    
    # åˆ†æç»“æœå’Œå»ºè®®
    person_detection_rate = stats['frames_with_person'] / stats['total_frames']
    wave_in_person_rate = (stats['wave_in_person_area'] + stats['nowave_in_person_area']) / max(stats['persons_detected'], 1)
    
    print(f"\n=== åˆ†æç»“è®º ===")
    
    if person_detection_rate < 0.1:
        print("ğŸ”´ äººç‰©æ£€æµ‹ç‡è¿‡ä½ï¼å¯èƒ½çš„é—®é¢˜ï¼š")
        print("- æ‘„åƒå¤´è§’åº¦ä¸ä½³")
        print("- äººç‰©åœ¨ç”»é¢ä¸­å¤ªå°")
        print("- å…‰çº¿æ¡ä»¶ä¸å¥½")
        print("- äººç‰©è¢«é®æŒ¡")
    elif person_detection_rate < 0.5:
        print("ğŸŸ¡ äººç‰©æ£€æµ‹ç‡ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–æ‘„åƒå¤´ä½ç½®")
    else:
        print("ğŸŸ¢ äººç‰©æ£€æµ‹è‰¯å¥½")
    
    if stats['wave_in_person_area'] + stats['nowave_in_person_area'] == 0:
        print("ğŸ”´ åœ¨äººç‰©åŒºåŸŸå†…æœªæ£€æµ‹åˆ°ä»»ä½•æŒ¥æ‰‹åŠ¨ä½œï¼")
        print("å¼ºçƒˆå»ºè®®é‡æ–°è®­ç»ƒæŒ¥æ‰‹æ£€æµ‹æ¨¡å‹")
    else:
        print("ğŸŸ¢ åœ¨äººç‰©åŒºåŸŸå†…æ£€æµ‹åˆ°æŒ¥æ‰‹åŠ¨ä½œ")
        if stats['direct_wave_detection'] + stats['direct_nowave_detection'] > 0:
            print("âš ï¸  ä½†ä¹Ÿæœ‰äººç‰©åŒºåŸŸå¤–çš„è¯¯æ£€æµ‹ï¼Œå»ºè®®ä¼˜åŒ–æ¨¡å‹")
    
    if save_samples:
        print(f"\næ ·æœ¬å›¾ç‰‡å·²ä¿å­˜åˆ°: {sample_dir}")
    
    return True

def bbox_overlap(bbox1, bbox2, threshold=0.3):
    """
    æ£€æŸ¥ä¸¤ä¸ªè¾¹ç•Œæ¡†æ˜¯å¦é‡å 
    
    Args:
        bbox1: [x1, y1, x2, y2]
        bbox2: [x1, y1, x2, y2]
        threshold: é‡å é˜ˆå€¼
    """
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2
    
    # è®¡ç®—äº¤é›†
    x1_inter = max(x1_1, x1_2)
    y1_inter = max(y1_1, y1_2)
    x2_inter = min(x2_1, x2_2)
    y2_inter = min(y2_1, y2_2)
    
    if x2_inter <= x1_inter or y2_inter <= y1_inter:
        return False
    
    # è®¡ç®—äº¤é›†é¢ç§¯
    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)
    
    # è®¡ç®—å¹¶é›†é¢ç§¯
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union_area = area1 + area2 - inter_area
    
    # è®¡ç®—IoU
    iou = inter_area / union_area if union_area > 0 else 0
    
    return iou >= threshold

def main():
    """ä¸»å‡½æ•°"""
    video_path = r"C:\c\wave_hands\test_videos_20250622_100947\B605_3min_20250622_100957.mp4"
    
    print("=== ä¸¤é˜¶æ®µæ£€æµ‹åˆ†æï¼šäººç‰©æ£€æµ‹ + æŒ¥æ‰‹è¯†åˆ« ===")
    print(f"è§†é¢‘æ–‡ä»¶: {video_path}")
    
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    # åŠ è½½é…ç½®
    try:
        config = load_config()
    except Exception as e:
        print(f"è¯»å–é…ç½®å¤±è´¥: {e}")
        return
    
    # å¼€å§‹ä¸¤é˜¶æ®µåˆ†æ
    success = analyze_person_detection(video_path, config, save_samples=True)
    
    if success:
        print(f"\n=== æ”¹è¿›å»ºè®® ===")
        print("1. å¦‚æœäººç‰©æ£€æµ‹ç‡é«˜ä½†æŒ¥æ‰‹æ£€æµ‹ç‡ä½ï¼Œå»ºè®®é‡æ–°è®­ç»ƒæŒ¥æ‰‹æ¨¡å‹")
        print("2. å¯ä»¥è€ƒè™‘å…ˆè£å‰ªäººç‰©åŒºåŸŸï¼Œå†è¿›è¡ŒæŒ¥æ‰‹æ£€æµ‹ä»¥æé«˜å‡†ç¡®ç‡")
        print("3. å¯ä»¥ç»“åˆæ—¶åºä¿¡æ¯ï¼Œåˆ†æè¿ç»­å¸§ä¸­çš„åŠ¨ä½œå˜åŒ–")
        print("4. å¯ä»¥æ·»åŠ å§¿æ€ä¼°è®¡æ¥æ›´ç²¾ç¡®åœ°åˆ†ææŒ¥æ‰‹åŠ¨ä½œ")

if __name__ == '__main__':
    main() 